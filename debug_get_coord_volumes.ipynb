{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from mvn.utils import multiview\n",
    "\n",
    "from mvn.datasets.cmu import CMUSceneDataset\n",
    "from mvn.datasets.human36m import Human36MMultiViewDataset, Human36MSingleViewDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "from itertools import islice\n",
    "from tqdm import tqdm_notebook\n",
    "import pickle\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from mvn.utils.img import image_batch_to_numpy, denormalize_image\n",
    "from mvn.models.temporal import TemporalModel, TemporalModelBase\n",
    "from mvn.models.basic import MVNetVolumetricHybridResNet_2, MVNetVolumetricHybridResNet_temporal\n",
    "from mvn.utils.multiview import project_3d_points_to_image_plane_without_distortion\n",
    "from mvn.utils.vis import draw_2d_pose\n",
    "\n",
    "from mvn.utils import img\n",
    "from mvn.utils import multiview\n",
    "from mvn.utils import volumetric\n",
    "from mvn.utils import op\n",
    "from mvn.utils import vis\n",
    "from mvn.utils import misc\n",
    "from mvn.utils import cfg\n",
    "\n",
    "from time import time\n",
    "\n",
    "from easydict import EasyDict\n",
    "\n",
    "from mvn.datasets import cmu, kth\n",
    "from mvn.datasets import utils as dataset_utils\n",
    "from mvn.datasets.human36m import Human36MMultiViewDataset, Human36MSingleViewDataset\n",
    "\n",
    "from train import setup_human36m_dataloaders\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "retval = {\n",
    "    'subject_names': ['S1', 'S5', 'S6', 'S7', 'S8', 'S9', 'S11'],\n",
    "    'camera_names': ['54138969', '55011271', '58860488', '60457274'],\n",
    "    'action_names': [\n",
    "        'Directions-1', 'Directions-2',\n",
    "        'Discussion-1', 'Discussion-2',\n",
    "        'Eating-1', 'Eating-2',\n",
    "        'Greeting-1', 'Greeting-2',\n",
    "        'Phoning-1', 'Phoning-2',\n",
    "        'Posing-1', 'Posing-2',\n",
    "        'Purchases-1', 'Purchases-2',\n",
    "        'Sitting-1', 'Sitting-2',\n",
    "        'SittingDown-1', 'SittingDown-2',\n",
    "        'Smoking-1', 'Smoking-2',\n",
    "        'TakingPhoto-1', 'TakingPhoto-2',\n",
    "        'Waiting-1', 'Waiting-2',\n",
    "        'Walking-1', 'Walking-2',\n",
    "        'WalkingDog-1', 'WalkingDog-2',\n",
    "        'WalkingTogether-1', 'WalkingTogether-2']\n",
    "}\n",
    "# import nonechucks\n",
    "\n",
    "device = torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_root = '../../logs/vanilla_v2v/h36_sv_dist_default_bs2-5@10.10.2019-17:58:03'\n",
    "# config_path = experiment_root + '/config.yaml'\n",
    "\n",
    "config_path = './experiments/paper/human36m/vol_2stage2/human36m_v2v_softmax.yaml'\n",
    "\n",
    "config = cfg.load_config(config_path)\n",
    "\n",
    "# config.opt.val_batch_size=1\n",
    "# config.dataset.val.retain_every_n_frames_in_test = 1\n",
    "\n",
    "train_loader, val_loader = setup_human36m_dataloaders(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints = batch['keypoints_3d']\n",
    "volume_size = 64\n",
    "cuboid_side = 2500\n",
    "cuboids = []\n",
    "sides = np.array([cuboid_side, cuboid_side, cuboid_side])\n",
    "\n",
    "# keypoints = keypoints[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_coord_volumes_old(self, \n",
    "                            batch, \n",
    "                            cuboid_side, \n",
    "                            volume_size, \n",
    "                            device, \n",
    "                            determine_base_point = False, \n",
    "                            tri_keypoints_3d = None\n",
    "                            ):\n",
    "        '''\n",
    "        determine_base_point (bool, optional): If set `True`, we determine it, using pre-calculated values, ground-truth or triangulation,\n",
    "                                               if set `False`, we use default base point in the coodninate origin.              \n",
    "        tri_keypoints_3d (torch.tensor, optional): keypoints given by triangulation, to extract base_point from them, \n",
    "                                                    determine_base_point should be True\n",
    "        '''\n",
    "        # build coord volumes\n",
    "\n",
    "\n",
    "        cuboids = []\n",
    "        batch_size = batch['keypoints_3d'].shape[0]\n",
    "        coord_volumes = torch.zeros(batch_size, volume_size, volume_size, volume_size, 3, device=device)\n",
    "\n",
    "        for batch_i in range(batch_size):\n",
    "\n",
    "            # default base_point    \n",
    "            base_point = np.array([0, 0, 0])      \n",
    "\n",
    "            if determine_base_point:    \n",
    "                if self.use_precalculated_pelvis or self.use_gt_pelvis:\n",
    "                    keypoints_3d = batch['keypoints_3d'][batch_i] # [bs, dt, 17,4]\n",
    "                else:\n",
    "                    # here we have to determine pelvis by ourselves\n",
    "                    keypoints_3d = tri_keypoints_3d[batch_i].detach().cpu().numpy()\n",
    "\n",
    "                # get pelvis from keypoints   \n",
    "                if self.use_separate_v2v_for_basepoint:\n",
    "                    base_point = keypoints_3d[0, :3]\n",
    "                else:         \n",
    "                    if self.kind == \"coco\":\n",
    "                        base_point = (keypoints_3d[11, :3] + keypoints_3d[12, :3]) / 2\n",
    "                    elif self.kind == \"mpii\":\n",
    "                        base_point = keypoints_3d[6, :3]\n",
    "\n",
    "            # build cuboid\n",
    "            sides = np.array([cuboid_side, cuboid_side, cuboid_side])\n",
    "            # origin of the new coordinate system\n",
    "            position = base_point - sides / 2\n",
    "            cuboid = volumetric.Cuboid3D(position, sides)\n",
    "\n",
    "            cuboids.append(cuboid)\n",
    "\n",
    "            # build coord volume\n",
    "            xxx, yyy, zzz = torch.meshgrid(torch.arange(volume_size, device=device),\n",
    "                                            torch.arange(volume_size, device=device),\n",
    "                                             torch.arange(volume_size, device=device))\n",
    "\n",
    "            grid = torch.stack([xxx, yyy, zzz], dim=-1).type(torch.float)\n",
    "            grid = grid.reshape((-1, 3))\n",
    "\n",
    "            grid_coord = torch.zeros_like(grid)\n",
    "            grid_coord[:, 0] = position[0] + (sides[0] / (volume_size - 1)) * grid[:, 0]\n",
    "            grid_coord[:, 1] = position[1] + (sides[1] / (volume_size - 1)) * grid[:, 1]\n",
    "            grid_coord[:, 2] = position[2] + (sides[2] / (volume_size - 1)) * grid[:, 2]\n",
    "\n",
    "            coord_volume = grid_coord.reshape(volume_size, volume_size, volume_size, 3)\n",
    "\n",
    "            if self.kind == \"coco\":\n",
    "                axis = [0, 1, 0]  # y axis\n",
    "            elif self.kind == \"mpii\":\n",
    "                axis = [0, 0, 1]  # z axis\n",
    "\n",
    "            # random rotation\n",
    "            if self.training and self.rotation and determine_base_point:\n",
    "                theta = np.random.uniform(0.0, 2 * np.pi)\n",
    "\n",
    "                # random rotation at the second stage\n",
    "                center = torch.from_numpy(base_point).type(torch.float).to(device)\n",
    "                coord_volume = coord_volume - center\n",
    "                coord_volume = volumetric.rotate_coord_volume(coord_volume, theta, axis)\n",
    "                coord_volume = coord_volume + center\n",
    "\n",
    "            # transfer\n",
    "            if self.transfer_cmu_to_human36m:\n",
    "                coord_volume = coord_volume.permute(0, 2, 1, 3)\n",
    "                inv_idx = torch.arange(coord_volume.shape[1] - 1, -1, -1).long().to(device)\n",
    "                coord_volume = coord_volume.index_select(1, inv_idx)\n",
    "\n",
    "            coord_volumes[batch_i] = coord_volume        \n",
    "\n",
    "        return coord_volumes, cuboids    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coord_volumes(self, \n",
    "                        cuboid_side, \n",
    "                        volume_size, \n",
    "                        device, \n",
    "                        keypoints = None,\n",
    "                        batch_size = None,\n",
    "                        dt = None\n",
    "                        ):\n",
    "    \n",
    "    use_origin_basepoint = keypoints is None\n",
    "    bs_dt = (batch_size, dt) if use_origin_basepoint else keypoints.shape[:-2]\n",
    "    \n",
    "    # default base_point is the coordinate's origin\n",
    "    base_point = np.zeros((*bs_dt, 3))\n",
    "    \n",
    "    if not use_origin_basepoint:    \n",
    "        # get root (pelvis) from keypoints   \n",
    "        if self.kind == \"coco\":\n",
    "            base_point = (keypoints[...,11, :3] + keypoints[...,12, :3]) / 2\n",
    "        elif self.kind == \"mpii\":\n",
    "            base_point = keypoints[..., 6, :3] \n",
    "\n",
    "    position = torch.tensor(base_point - sides / 2, dtype=torch.float).to(device)\n",
    "\n",
    "    # build coord volume\n",
    "    xxx, yyy, zzz = torch.meshgrid(torch.arange(volume_size, device=device),\n",
    "                                    torch.arange(volume_size, device=device),\n",
    "                                     torch.arange(volume_size, device=device))\n",
    "    grid = torch.stack([xxx, yyy, zzz], dim=-1).type(torch.float)\n",
    "    grid = grid.view((-1, 3))\n",
    "    grid = grid.view(*[1]*len(bs_dt), *grid.shape).repeat(*keypoints.shape[:-2], *[1]*len(grid.shape))\n",
    "\n",
    "    grid[..., 0] = position[..., 0].unsqueeze(-1) + (sides[0] / (volume_size - 1)) * grid[..., 0]\n",
    "    grid[..., 1] = position[..., 1].unsqueeze(-1) + (sides[1] / (volume_size - 1)) * grid[..., 1]\n",
    "    grid[..., 2] = position[..., 2].unsqueeze(-1) + (sides[2] / (volume_size - 1)) * grid[..., 2]\n",
    "    \n",
    "    if self.kind == \"coco\":\n",
    "        axis = [0, 1, 0]  # y axis\n",
    "    elif self.kind == \"mpii\":\n",
    "        axis = [0, 0, 1]  # z axis\n",
    "        \n",
    "    # random rotation\n",
    "    if self.training and self.rotation:    \n",
    "        \n",
    "        center = torch.from_numpy(base_point).type(torch.float).to(device).unsqueeze(-2)\n",
    "        grid = grid - center\n",
    "        \n",
    "        grid = torch.stack([volumetric.rotate_coord_volume(coord_grid,\\\n",
    "                            np.random.uniform(0.0, 2 * np.pi), axis) for coord_grid in grid])\n",
    "        \n",
    "        grid = grid + center\n",
    "    \n",
    "    grid = grid.view(*bs_dt, volume_size, volume_size, volume_size, 3)\n",
    "    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_shorted =  batch.copy()\n",
    "batch_shorted['keypoints_3d'] = batch_shorted['keypoints_3d'][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EasyDict({'training': True,\n",
    "                  'rotation':False,\n",
    "                  'kind':'mpii',\n",
    "                  'transfer_cmu_to_human36m':False,\n",
    "                  'use_precalculated_pelvis': False,\n",
    "                  'use_gt_pelvis': True,\n",
    "                  'use_separate_v2v_for_basepoint': False})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_t = []\n",
    "grid_old_t = []\n",
    "sizes = list(range(1,40))\n",
    "\n",
    "for i in tqdm_notebook(sizes):\n",
    "    \n",
    "    keypoints = np.random.randn(i,17,4)\n",
    "    batch_shorted['keypoints_3d'] = keypoints\n",
    "    \n",
    "    \n",
    "    t1 = time()\n",
    "    grid = get_coord_volumes(model, \n",
    "                            cuboid_side, \n",
    "                            volume_size, \n",
    "                            device, \n",
    "                            keypoints = keypoints)\n",
    "\n",
    "    t2 = time()\n",
    "    grid_old = get_coord_volumes_old(model, \n",
    "                                    batch_shorted, \n",
    "                                    cuboid_side, \n",
    "                                    volume_size, \n",
    "                                    device, \n",
    "                                    determine_base_point = True, \n",
    "                                    tri_keypoints_3d = None\n",
    "                                    )\n",
    "\n",
    "    t3 = time()\n",
    "    \n",
    "    grid_t += [round(t2-t1,4)]\n",
    "    grid_old_t += [round(t3-t2,4)]\n",
    "    \n",
    "    assert bool(torch.all(grid == grid_old[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks = sizes\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(grid_old_t, label='old_coord_volume_generator')\n",
    "plt.plot(grid_t, 'r', label='new_coord_volume_generator')\n",
    "plt.xticks(ticks = range(len(xticks)), labels=xticks)\n",
    "plt.xlabel('batch_size')\n",
    "plt.ylabel('time, sec.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
