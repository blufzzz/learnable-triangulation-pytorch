{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def adaptive_instance_normalization(content_feat, style_feat):\n",
    "    assert (content_feat.size()[:2] == style_feat.size()[:2])\n",
    "    size = content_feat.size()\n",
    "    style_mean, style_std = calc_mean_std(style_feat)\n",
    "    content_mean, content_std = calc_mean_std(content_feat)\n",
    "\n",
    "    normalized_feat = (content_feat - content_mean.expand(\n",
    "        size)) / content_std.expand(size)\n",
    "    return normalized_feat * style_std.expand(size) + style_mean.expand(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0,1,2,3,4][1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2VecModel(nn.Module):\n",
    "    \"\"\"docstring for Seq2VecModel\"\"\"\n",
    "    def __init__(self, features_dim, hidden_dim = 512):\n",
    "        super(Seq2VecModel, self).__init__()\n",
    "        self.features_dim = features_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.feature2vector = nn.Sequential(nn.Conv2d(self.features_dim,128,3),\n",
    "                               nn.BatchNorm2d(128),\n",
    "                               nn.ReLU(),\n",
    "                               nn.MaxPool2d(2),\n",
    "                               nn.Conv2d(128,64,3),\n",
    "                               nn.BatchNorm2d(64),\n",
    "                               nn.ReLU(),\n",
    "                               nn.MaxPool2d(2),\n",
    "                               nn.Conv2d(64,32,1),\n",
    "                               nn.BatchNorm2d(32),\n",
    "                               nn.ReLU(),\n",
    "                               nn.MaxPool2d(2),\n",
    "                               nn.Conv2d(32,16,1),\n",
    "                               nn.BatchNorm2d(16),\n",
    "                               nn.ReLU(),\n",
    "                               nn.MaxPool2d(2))\n",
    "        self.lstm = nn.LSTM(400, 512, batch_first=True)\n",
    "        \n",
    "    def forward(self, features):\n",
    "        # [batch size, dt, 256, 96, 96]\n",
    "\n",
    "        features_shape = features.shape[2:]\n",
    "        batch_size, dt = features.shape[:2]\n",
    "        vectors = self.feature2vector(features.view(-1, *features_shape))\n",
    "        vectors = vectors.view(batch_size, dt, -1)\n",
    "        (h0, c0) = torch.randn(1, batch_size, self.hidden_dim), torch.randn(1, batch_size, self.hidden_dim)\n",
    "        output, (hn, cn) = self.lstm(vectors, (h0, c0))\n",
    "        return output[:,-1,...]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = torch.randn(2,3,256, 96, 96)\n",
    "\n",
    "m = Seq2VecModel(256)\n",
    "m(features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1936])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature2vector = nn.Sequential(nn.Conv2d(256,128,3),\n",
    "                               nn.BatchNorm2d(128),\n",
    "                               nn.ReLU(),\n",
    "                               nn.MaxPool2d(2),\n",
    "                               nn.Conv2d(128,64,3),\n",
    "                               nn.BatchNorm2d(64),\n",
    "                               nn.ReLU(),\n",
    "                               nn.MaxPool2d(2),\n",
    "                               nn.Conv2d(64,32,1),\n",
    "                               nn.BatchNorm2d(32),\n",
    "                               nn.ReLU(),\n",
    "                               nn.MaxPool2d(2),\n",
    "                               nn.Conv2d(32,16,1),\n",
    "                               nn.BatchNorm2d(16),\n",
    "                               nn.ReLU(),\n",
    "                               nn.MaxPool2d(2))\n",
    "\n",
    "features_shape = features.shape[2:]\n",
    "feature2vector(features.view(-1, *features_shape)).view(6,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_std(feat, eps=1e-5):\n",
    "    # eps is a small value added to the variance to avoid divide-by-zero.\n",
    "    size = feat.size()\n",
    "    assert (len(size) == 4)\n",
    "    N, C = size[:2]\n",
    "    feat_var = feat.view(N, C, -1).var(dim=2) + eps\n",
    "    feat_std = feat_var.sqrt().view(N, C, 1, 1)\n",
    "    feat_mean = feat.view(N, C, -1).mean(dim=2).view(N, C, 1, 1)\n",
    "    return feat_mean, feat_std\n",
    "\n",
    "\n",
    "def adaptive_instance_normalization(content_feat, style_feat):\n",
    "    assert (content_feat.size()[:2] == style_feat.size()[:2])\n",
    "    size = content_feat.size()\n",
    "    style_mean, style_std = calc_mean_std(style_feat)\n",
    "    content_mean, content_std = calc_mean_std(content_feat)\n",
    "\n",
    "    normalized_feat = (content_feat - content_mean.expand(\n",
    "        size)) / content_std.expand(size)\n",
    "    return normalized_feat * style_std.expand(size) + style_mean.expand(size)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaIN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AdaIN, self).__init__()\n",
    "    def forward(self, features, params):\n",
    "        # [batch_size, C, D1, D2, D3]\n",
    "        size = features.size()\n",
    "        batch_size, C = features.shape[:2]\n",
    "        features_mean = features.view(batch_size, C, -1).mean(-1).view(batch_size, C,1,1,1)\n",
    "        features_std = features.view(batch_size, C, -1).std(-1).view(batch_size, C,1,1,1)\n",
    "        norm_features = (features - features_mean) / features_std\n",
    "        return norm_features * params[0] + params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 64, 64, 64])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = AdaIN()\n",
    "a(features, [1,1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
