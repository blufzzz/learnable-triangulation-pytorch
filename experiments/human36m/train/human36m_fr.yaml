title: "human36m_vol_temporal_fr_adain_softmax"
kind: "human36m"
vis_freq: 100
vis_n_elements: 10

image_shape: [384, 384]

opt:
  n_objects_per_epoch: 15000
  n_epochs: 9999

  batch_size: 5
  val_batch_size: 5

  lr: 0.001
  process_features_lr: 0.001

kind: "mpii"
features_regressor: "conv2d_unet"
intermediate_features_dim: 32
features_regressor_base_channels: 2

init_weights: false
checkpoint: ""

backbone:
  name: "resnet152"
  style: "simple"

  init_weights: true
  checkpoint: "./data/pose_resnet_4.5_pixels_human36m.pth"

  num_joints: 17
  num_layers: 152

  alg_confidences: false
  vol_confidences: false
  return_heatmaps: false
  return_backbone: false


dataset:
  kind: "human36m"
  dt: 3
  dilation: 5
  singleview: true
  pivot_type: 'first'

  train:
    h36m_root: "/media/hpc2_storage/ibulygin/h36m-fetch/processed/"
    labels_path: "/media/hpc2_storage/ibulygin/human36m-preprocessing/human36m-multiview-labels-GTbboxes.npy"
    pred_results_path: 

    with_damaged_actions: true
    undistort_images: false

    scale_bbox: 1.0

    shuffle: true
    randomize_n_views: false
    min_n_views: null
    max_n_views: null
    num_workers: 8

  val:
    pivot_type: 'first'
    h36m_root: "/media/hpc2_storage/ibulygin/h36m-fetch/processed/"
    labels_path: "/media/hpc2_storage/ibulygin/human36m-preprocessing/human36m-multiview-labels-GTbboxes.npy"
    pred_results_path: 

    with_damaged_actions: true
    undistort_images: false

    scale_bbox: 1.0

    shuffle: false
    randomize_n_views: false
    min_n_views: null
    max_n_views: null
    num_workers: 8

    retain_every_n_frames_in_test: 30
