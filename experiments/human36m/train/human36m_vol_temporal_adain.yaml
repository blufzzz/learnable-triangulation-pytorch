title: "human36m_vol_temporal_lstm_adain_softmax"
kind: "human36m"
vis_freq: 1000
vis_n_elements: 10
distributed_train: true
image_shape: [384, 384]

opt:
  criterion: "MAE"

  use_volumetric_ce_loss: true
  volumetric_ce_loss_weight: 0.01

  n_objects_per_epoch: 10000
  n_epochs: 9999
  dump_weights: False

  batch_size: 1
  val_batch_size: 1

  lr: 0.0001
  process_features_lr: 0.001
  volume_net_lr: 0.001
  affine_mappings_lr: 0.001
  features_sequence_to_vector_lr: 0.001
  encoder_lr: 0.001
  scale_keypoints_3d: 0.1

  save_model: false


model:
  name: "vol_temporal_adain"
  kind: "mpii"
  volume_aggregation_method: "no_aggregation"
  adain_type: 'all' # if 'all' then normalization_type: 'adain' or 'ada-group_norm'
  
  volume_features_dim: 64 #32
  style_vector_dim: 256 #256 #256

  encoder_type: "backbone"
  encoder_capacity_multiplier: 2
  encoder_normalization_type: 'group_norm'
  encoded_feature_space: 1024

  f2v_type: 'lstm'
  f2v_normalization_type: 'group_norm'
  f2v_intermediate_channels: 512
  kernel_size: 3 #3 # for cnn only 
  
  include_pivot: false # including pivot getting thigs worse
  style_grad_for_backbone: false
  v2v_normalization_type: 'group-ada_norm' #'ada-group_norm'

  init_weights: false
  checkpoint: ""

  use_gt_pelvis: true
  use_precalculated_pelvis: false
  use_volumetric_pelvis: false

  cuboid_side: 2500 #1000 #2500.0
  cuboid_multiplier: 1.0
  rotation: false


  volume_size: 16
  volume_multiplier: 1.0
  volume_softmax: true

  transfer_cmu_to_human36m: false

  backbone:
    name: "resnet152"  #"resnet50" #"resnet152"
    style: "simple"

    group_norm: true
    init_weights: true
    checkpoint: "./data/pose_resnet_4.5_pixels_human36m.pth"

    num_joints: 17
    num_layers: 152 #50 #152

    alg_confidences: false
    vol_confidences: false
    return_heatmaps: false
    return_bottleneck: true

dataset:
  kind: "human36m"
  dt: 8
  dilation: 3
  singleview: true
  pivot_type: 'first'

  train:
    h36m_root: "/media/hpc2_storage/ibulygin/h36m-fetch/processed/"
    labels_path: "/media/hpc2_storage/ibulygin/human36m-preprocessing/human36m-multiview-labels-GTbboxes.npy"
    pred_results_path:

    with_damaged_actions: true
    undistort_images: false

    scale_bbox: 1.0

    shuffle: true
    randomize_n_views: false
    min_n_views: null
    max_n_views: null
    num_workers: 8

  val:
    h36m_root: "/media/hpc2_storage/ibulygin/h36m-fetch/processed/"
    labels_path: "/media/hpc2_storage/ibulygin/human36m-preprocessing/human36m-multiview-labels-GTbboxes.npy"
    pred_results_path: 

    with_damaged_actions: true
    undistort_images: false

    scale_bbox: 1.0

    shuffle: false
    randomize_n_views: false
    min_n_views: null
    max_n_views: null
    num_workers: 8

    retain_every_n_frames_in_test: 30
